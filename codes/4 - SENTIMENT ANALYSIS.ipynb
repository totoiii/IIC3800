{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IIC-3800 Tópicos en CC - NLP UC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Versiones de librerías, python 3.8.10\n",
    "\n",
    "- numpy 1.20.3\n",
    "- nltk 3.7\n",
    "- lime 0.2.0.1\n",
    "- spacy 3.5.1\n",
    "- gcsfs 2023.3.0\n",
    "- protobuf 3.20.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import product_reviews_1\n",
    "camera_reviews = product_reviews_1.reviews('Canon_G3.txt')\n",
    "\n",
    "reviews = []\n",
    "\n",
    "for review in camera_reviews:\n",
    "    sentences = []\n",
    "    for sentence in review.sents():\n",
    "        text = \" \".join(sentence)\n",
    "        sentences.append(text)\n",
    "    document = \" \".join(sentences)\n",
    "    reviews.append(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Load stop-words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize tokenizer\n",
    "# It's also possible to try with a stemmer or to mix a stemmer and a lemmatizer\n",
    "tokenizer = RegexpTokenizer('[\\'a-zA-Z]+')\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenize(document):\n",
    "    words = []\n",
    "\n",
    "    for sentence in sent_tokenize(document):\n",
    "        tokens = [lemmatizer.lemmatize(t.lower()) for t in tokenizer.tokenize(sentence) if t.lower() not in stop_words and len(t) > 2]\n",
    "        words += tokens\n",
    "    \n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for review in reviews:\n",
    "    document = tokenize(review)\n",
    "    corpus.append(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create an instance of SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer() # compound in [-1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver documentación de vader en: https://www.nltk.org/api/nltk.sentiment.vader.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for i in range(len(corpus)):\n",
    "    if analyzer.polarity_scores(corpus[i])['compound'] > 0.2: \n",
    "        label.append('Positive') # positive sentiment\n",
    "    elif analyzer.polarity_scores(corpus[i])['compound'] < -0.2:\n",
    "        label.append('Negative') # negative sentiment\n",
    "    else:\n",
    "        label.append('Neutral') # neutral sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>polarities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recently purchased canon powershot extremely s...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yep first digital camera toy software engineer...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>extensive research comparing different megapix...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bought canon month ago say satisfied taken hun...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>camera one full day say wonderful photo qualit...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>positive slr like programming exposure control...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>camera wonderful set feature lcd screen pull r...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>recent price drop made best bargain digital ca...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>recommend unreservedly powershot potential buy...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>else say camera work make photograph work want...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>great camera canon give ton control photo buff...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>first digital camera pleased know whole lot ph...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>received camera two day ago already love featu...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>camera significantly noise iso nikon</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bought camera day ago get used first feeling p...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bought last week amazon got great deal reputab...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>maybe lack experience found shot camera disapp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>long time user highly responsive film slrs pro...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>month pleased decision perfect camera photo ho...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>reading positive review camera leading consume...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>great fan set somewhat negative expectation di...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>love thought would upgrade big mistake problem...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>shopping digital camera looked nikon olympus n...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>powershot great camera help photographer take ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>catch canon camera perhaps digital camera unre...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>first digital camera could happier plan sellin...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>canon perhaps best camera tried sony carl zeis...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>used canon powershot year loved flaw learned d...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>looking buy digital camera long time finally d...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>read review spec performance opinion perfectly...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>first digital camera pleased far wanted someth...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>best camera ever image quality color function ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>write many review compelled camera first forem...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>spent lot time comparing different camera real...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>owned camera short time would give anything su...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>bought product month ago used variety situatio...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>far finest camera price category ever used als...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>camera closest perfect digicam megapixel beat ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>camera work art science understood take great ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>see rank product since merchant amazon collabo...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>camera major design flaw look viewfinder lcd b...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>using powershot nearly year wanted upgrade meg...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>using six week proven advertised hand comparis...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>canon improves almost way fact beat nikon cool...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>definetely great camera proven canon built qua...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review polarities\n",
       "0   recently purchased canon powershot extremely s...   Positive\n",
       "1   yep first digital camera toy software engineer...   Positive\n",
       "2   extensive research comparing different megapix...   Positive\n",
       "3   bought canon month ago say satisfied taken hun...   Positive\n",
       "4   camera one full day say wonderful photo qualit...   Positive\n",
       "5   positive slr like programming exposure control...   Positive\n",
       "6   camera wonderful set feature lcd screen pull r...   Positive\n",
       "7   recent price drop made best bargain digital ca...   Positive\n",
       "8   recommend unreservedly powershot potential buy...   Positive\n",
       "9   else say camera work make photograph work want...   Positive\n",
       "10  great camera canon give ton control photo buff...   Positive\n",
       "11  first digital camera pleased know whole lot ph...   Positive\n",
       "12  received camera two day ago already love featu...   Positive\n",
       "13               camera significantly noise iso nikon    Neutral\n",
       "14  bought camera day ago get used first feeling p...   Positive\n",
       "15  bought last week amazon got great deal reputab...   Positive\n",
       "16  maybe lack experience found shot camera disapp...   Positive\n",
       "17  long time user highly responsive film slrs pro...   Positive\n",
       "18  month pleased decision perfect camera photo ho...   Positive\n",
       "19  reading positive review camera leading consume...   Positive\n",
       "20  great fan set somewhat negative expectation di...   Positive\n",
       "21  love thought would upgrade big mistake problem...   Negative\n",
       "22  shopping digital camera looked nikon olympus n...   Positive\n",
       "23  powershot great camera help photographer take ...   Positive\n",
       "24  catch canon camera perhaps digital camera unre...   Positive\n",
       "25  first digital camera could happier plan sellin...   Positive\n",
       "26  canon perhaps best camera tried sony carl zeis...   Positive\n",
       "27  used canon powershot year loved flaw learned d...   Positive\n",
       "28  looking buy digital camera long time finally d...   Positive\n",
       "29  read review spec performance opinion perfectly...   Positive\n",
       "30  first digital camera pleased far wanted someth...   Positive\n",
       "31  best camera ever image quality color function ...   Positive\n",
       "32  write many review compelled camera first forem...   Positive\n",
       "33  spent lot time comparing different camera real...   Positive\n",
       "34  owned camera short time would give anything su...   Positive\n",
       "35  bought product month ago used variety situatio...   Positive\n",
       "36  far finest camera price category ever used als...   Positive\n",
       "37  camera closest perfect digicam megapixel beat ...   Positive\n",
       "38  camera work art science understood take great ...   Positive\n",
       "39  see rank product since merchant amazon collabo...   Positive\n",
       "40  camera major design flaw look viewfinder lcd b...   Negative\n",
       "41  using powershot nearly year wanted upgrade meg...   Positive\n",
       "42  using six week proven advertised hand comparis...   Positive\n",
       "43  canon improves almost way fact beat nikon cool...   Positive\n",
       "44  definetely great camera proven canon built qua...   Positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(corpus, columns = ['review'])\n",
    "df['polarities'] = label\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised sentiment analysis (training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-78044fd3cd00>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv('gs://nlp_amazon_data/train.ft.txt', sep=\"__label__\", header = None)\n"
     ]
    }
   ],
   "source": [
    "# load in dataset and separate by the __label__ classifier in the text file\n",
    "data = pd.read_csv('gs://nlp_amazon_data/train.ft.txt', sep=\"__label__\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599995</th>\n",
       "      <td>Don't do it!!: The high chair looks great when...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599996</th>\n",
       "      <td>Looks nice, low functionality: I have used thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599997</th>\n",
       "      <td>compact, but hard to clean: We have a small ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599998</th>\n",
       "      <td>what is it saying?: not sure what this book is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599999</th>\n",
       "      <td>Makes My Blood Run Red-White-And-Blue: I agree...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    review sentiment\n",
       "0        Stuning even for the non-gamer: This sound tra...         2\n",
       "1        The best soundtrack ever to anything.: I'm rea...         2\n",
       "2        Amazing!: This soundtrack is my favorite music...         2\n",
       "3        Excellent Soundtrack: I truly like this soundt...         2\n",
       "4        Remember, Pull Your Jaw Off The Floor After He...         2\n",
       "...                                                    ...       ...\n",
       "3599995  Don't do it!!: The high chair looks great when...         1\n",
       "3599996  Looks nice, low functionality: I have used thi...         1\n",
       "3599997  compact, but hard to clean: We have a small ho...         1\n",
       "3599998  what is it saying?: not sure what this book is...         1\n",
       "3599999  Makes My Blood Run Red-White-And-Blue: I agree...         2\n",
       "\n",
       "[3600000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(0, inplace=True, axis=1)\n",
    "data['sentiment'] = data[1].str[0]\n",
    "data[1] = data[1].str[2:]\n",
    "data = data.rename(columns={1: 'review'})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3346284</th>\n",
       "      <td>Great cookbook.: I recently lost my husband, b...</td>\n",
       "      <td>2</td>\n",
       "      <td>great cookbook recently lost husband loved coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836622</th>\n",
       "      <td>perfect for occasional use on shower glass &amp; w...</td>\n",
       "      <td>2</td>\n",
       "      <td>perfect occasional use shower glass windshield...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36930</th>\n",
       "      <td>a good buy for this price: I bought this car s...</td>\n",
       "      <td>2</td>\n",
       "      <td>good buy price bought car seat backup car good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526701</th>\n",
       "      <td>As always, Céline and her incredible talent!: ...</td>\n",
       "      <td>2</td>\n",
       "      <td>céline incredible talent céline english record...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261667</th>\n",
       "      <td>flawed: Generally a very good resource, we sta...</td>\n",
       "      <td>1</td>\n",
       "      <td>flawed generally good resource stayed small lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    review sentiment  \\\n",
       "3346284  Great cookbook.: I recently lost my husband, b...         2   \n",
       "2836622  perfect for occasional use on shower glass & w...         2   \n",
       "36930    a good buy for this price: I bought this car s...         2   \n",
       "2526701  As always, Céline and her incredible talent!: ...         2   \n",
       "261667   flawed: Generally a very good resource, we sta...         1   \n",
       "\n",
       "                                                text_clean  \n",
       "3346284  great cookbook recently lost husband loved coo...  \n",
       "2836622  perfect occasional use shower glass windshield...  \n",
       "36930    good buy price bought car seat backup car good...  \n",
       "2526701  céline incredible talent céline english record...  \n",
       "261667   flawed generally good resource stayed small lo...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.blank(\"en\") # Create a blank pipeline of a given language class\n",
    "REGX_USERNAME = r\"@[A-Za-z0-9$-_@.&+]+\"\n",
    "\n",
    "def preprocessing(text):\n",
    "  text = text.lower()\n",
    "  text = re.sub(REGX_USERNAME, ' ', text)\n",
    "  tokens = [token.text for token in nlp(text)]\n",
    "  tokens = [t for t in tokens if t not in STOP_WORDS and t not in string.punctuation and len(t) > 2]\n",
    "  tokens = [t for t in tokens if not t.isdigit()]\n",
    "\n",
    "  return \" \".join(tokens)\n",
    "\n",
    "sample[\"text_clean\"] = sample[\"review\"].apply(preprocessing)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3346284</th>\n",
       "      <td>Great cookbook.: I recently lost my husband, b...</td>\n",
       "      <td>2</td>\n",
       "      <td>great cookbook recently lost husband loved coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836622</th>\n",
       "      <td>perfect for occasional use on shower glass &amp; w...</td>\n",
       "      <td>2</td>\n",
       "      <td>perfect occasional use shower glass windshield...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36930</th>\n",
       "      <td>a good buy for this price: I bought this car s...</td>\n",
       "      <td>2</td>\n",
       "      <td>good buy price bought car seat backup car good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526701</th>\n",
       "      <td>As always, Céline and her incredible talent!: ...</td>\n",
       "      <td>2</td>\n",
       "      <td>céline incredible talent céline english record...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261667</th>\n",
       "      <td>flawed: Generally a very good resource, we sta...</td>\n",
       "      <td>1</td>\n",
       "      <td>flawed generally good resource stayed small lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172193</th>\n",
       "      <td>Exactly what I wanted: The bumper caps fit as ...</td>\n",
       "      <td>2</td>\n",
       "      <td>exactly wanted bumper caps fit expected better...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346447</th>\n",
       "      <td>Eloquent discriptions, Savage vision, Fantasti...</td>\n",
       "      <td>2</td>\n",
       "      <td>eloquent discriptions savage vision fantastic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515569</th>\n",
       "      <td>looks good to me: I hope I never have to use i...</td>\n",
       "      <td>2</td>\n",
       "      <td>looks good hope use looks like quality piece h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101032</th>\n",
       "      <td>Disappointed: I am disappointed with this blow...</td>\n",
       "      <td>1</td>\n",
       "      <td>disappointed disappointed blower purchased blo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546437</th>\n",
       "      <td>Shame on Avon and Amazon.com: Do not buy the m...</td>\n",
       "      <td>1</td>\n",
       "      <td>shame avon amazon.com buy mass market edition ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    review sentiment  \\\n",
       "3346284  Great cookbook.: I recently lost my husband, b...         2   \n",
       "2836622  perfect for occasional use on shower glass & w...         2   \n",
       "36930    a good buy for this price: I bought this car s...         2   \n",
       "2526701  As always, Céline and her incredible talent!: ...         2   \n",
       "261667   flawed: Generally a very good resource, we sta...         1   \n",
       "...                                                    ...       ...   \n",
       "2172193  Exactly what I wanted: The bumper caps fit as ...         2   \n",
       "346447   Eloquent discriptions, Savage vision, Fantasti...         2   \n",
       "515569   looks good to me: I hope I never have to use i...         2   \n",
       "2101032  Disappointed: I am disappointed with this blow...         1   \n",
       "2546437  Shame on Avon and Amazon.com: Do not buy the m...         1   \n",
       "\n",
       "                                                text_clean  \n",
       "3346284  great cookbook recently lost husband loved coo...  \n",
       "2836622  perfect occasional use shower glass windshield...  \n",
       "36930    good buy price bought car seat backup car good...  \n",
       "2526701  céline incredible talent céline english record...  \n",
       "261667   flawed generally good resource stayed small lo...  \n",
       "...                                                    ...  \n",
       "2172193  exactly wanted bumper caps fit expected better...  \n",
       "346447   eloquent discriptions savage vision fantastic ...  \n",
       "515569   looks good hope use looks like quality piece h...  \n",
       "2101032  disappointed disappointed blower purchased blo...  \n",
       "2546437  shame avon amazon.com buy mass market edition ...  \n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(sample[[\"text_clean\", \"sentiment\"]].sample(frac=1).itertuples(index=False, name=None))\n",
    "train_data = dataset[:75000]  # 75%\n",
    "dev_data = dataset[75000:90000] # 15%\n",
    "test_data = dataset[90000:] # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data, outfile):\n",
    "    db = spacy.tokens.DocBin()\n",
    "    docs = []\n",
    "    for doc, label in nlp.pipe(data, as_tuples=True):\n",
    "        doc.cats[\"POS\"] = label == '2'\n",
    "        doc.cats[\"NEG\"] = label == '1'\n",
    "        db.add(doc)\n",
    "    \n",
    "    db.to_disk(outfile)\n",
    "convert(train_data, \"./train.spacy\")\n",
    "convert(dev_data, \"./dev.spacy\")\n",
    "convert(test_data, \"./test.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-15 12:21:09.684878: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-15 12:21:10.200898: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:21:10.200957: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:21:10.200964: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-15 12:21:11.160686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:21:11.160748: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:21:11.162258: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:21:11.162303: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:21:11.162331: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:21:11.162339: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
      "install the spacy-transformers package and re-run this command. The config\n",
      "generated now does not use transformers.\u001b[0m\n",
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: en\n",
      "- Pipeline: textcat\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy init config --lang en --pipeline textcat --optimize efficiency --force config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver documentación de config en: https://spacy.io/usage/training#quickstart\n",
    "\n",
    "Ver documentación de architectures en: https://spacy.io/api/architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-15 12:21:13.718929: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-15 12:21:14.212680: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:21:14.212745: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:21:14.212750: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-15 12:21:15.082407: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:21:15.082472: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:21:15.083968: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:21:15.084011: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:21:15.084041: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:21:15.084050: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "[2023-03-15 12:21:15,311] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
      "\u001b[38;5;4mℹ Saving to output directory: model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2023-03-15 12:21:15,548] [INFO] Set up nlp object from config\n",
      "[2023-03-15 12:21:15,554] [DEBUG] Loading corpus from path: dev.spacy\n",
      "[2023-03-15 12:21:15,555] [DEBUG] Loading corpus from path: train.spacy\n",
      "[2023-03-15 12:21:15,555] [INFO] Pipeline: ['textcat']\n",
      "[2023-03-15 12:21:15,557] [INFO] Created vocabulary\n",
      "[2023-03-15 12:21:15,557] [INFO] Finished initializing nlp object\n",
      "[2023-03-15 12:21:41,174] [INFO] Initialized pipeline components: ['textcat']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[2023-03-15 12:21:41,181] [DEBUG] Loading corpus from path: dev.spacy\n",
      "[2023-03-15 12:21:41,182] [DEBUG] Loading corpus from path: train.spacy\n",
      "[2023-03-15 12:21:41,183] [DEBUG] Removed existing output directory: model/model-best\n",
      "[2023-03-15 12:21:41,184] [DEBUG] Removed existing output directory: model/model-last\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTCAT  CATS_SCORE  SCORE \n",
      "---  ------  ------------  ----------  ------\n",
      "  0       0          0.25       54.28    0.54\n",
      "  0     200         43.48       77.18    0.77\n",
      "  0     400         35.26       79.64    0.80\n",
      "  0     600         30.45       81.22    0.81\n",
      "  0     800         25.83       82.04    0.82\n",
      "  0    1000         25.87       83.47    0.83\n",
      "  0    1200         25.04       84.14    0.84\n",
      "  0    1400         23.78       84.83    0.85\n",
      "  0    1600         23.32       85.14    0.85\n",
      "  0    1800         22.08       85.24    0.85\n",
      "  0    2000         20.67       85.63    0.86\n",
      "  0    2200         20.35       85.74    0.86\n",
      "  0    2400         20.93       86.22    0.86\n",
      "  0    2600         19.83       86.42    0.86\n",
      "  0    2800         20.02       86.57    0.87\n",
      "  0    3000         18.97       86.88    0.87\n",
      "  0    3200         19.20       86.99    0.87\n",
      "  0    3400         18.90       87.11    0.87\n",
      "  0    3600         18.81       87.13    0.87\n",
      "  0    3800         18.91       87.31    0.87\n",
      "  0    4000         18.22       87.29    0.87\n",
      "  1    4200         13.36       87.15    0.87\n",
      "  1    4400         12.24       87.20    0.87\n",
      "  1    4600         12.59       87.21    0.87\n",
      "  1    4800         13.12       87.39    0.87\n",
      "  1    5000         13.18       87.14    0.87\n",
      "  1    5200         13.15       87.15    0.87\n",
      "  1    5400         13.14       87.18    0.87\n",
      "  1    5600         13.55       87.17    0.87\n",
      "  1    5800         13.04       87.07    0.87\n",
      "  1    6000         14.31       87.17    0.87\n",
      "  1    6200         13.48       87.10    0.87\n",
      "  1    6400         14.49       87.11    0.87\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "model/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy --output model --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-15 12:26:19.385040: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-15 12:26:19.867377: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:26:19.867427: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:26:19.867432: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-15 12:26:20.734847: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:26:20.734905: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:26:20.736437: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:26:20.736481: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:26:20.736509: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:26:20.736518: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK                 100.00\n",
      "TEXTCAT (macro F)   87.85 \n",
      "SPEED               525002\n",
      "\n",
      "\u001b[1m\n",
      "=========================== Textcat F (per label) ===========================\u001b[0m\n",
      "\n",
      "          P       R       F\n",
      "POS   87.13   88.75   87.93\n",
      "NEG   88.60   86.95   87.77\n",
      "\n",
      "\u001b[1m\n",
      "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
      "\n",
      "      ROC AUC\n",
      "POS      0.94\n",
      "NEG      0.94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy evaluate ./model/model-best/ ./test.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POS': 0.1095241829752922, 'NEG': 0.8904758095741272} - This movie is unnecessarily long. At times it gets boring and hard to follow.\n",
      "{'POS': 0.44296127557754517, 'NEG': 0.5570387244224548} - I regretted ever purchasing or making order on this platform.\n"
     ]
    }
   ],
   "source": [
    "texts = [\"This movie is unnecessarily long. At times it gets boring and hard to follow.\", \"I regretted ever purchasing or making order on this platform.\"]\n",
    "nlp = spacy.load(\"./model/model-best\")\n",
    "for text in texts:\n",
    "    doc = nlp(preprocessing(text))\n",
    "    print(doc.cats,  \"-\",  text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
